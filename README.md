# Emodio: AI Vocal Biomarkers For Telepathy
 
Transform voices into emotional insights using AI.

## Overview

**Emodio â€“ Telepathy** is a real-time voice emotion recognition system that analyzes human speech and predicts emotional states using deep learning.  
The project provides a **complete end-to-end pipeline**, including model training, prediction, and a live graphical user interface (GUI).

This system is built as a **research and deployment prototype**, focusing on real-time processing and interpretability rather than clinical accuracy.

##  What is Telepathy?

In this project, **Telepathy** refers to the AIâ€™s ability to infer human emotional states from vocal patterns.  
Using LSTM-based deep learning models, the system identifies emotional cues embedded in speech.

### Supported Emotions
- Neutral  
- Happy  
- Sad  
- Angry  
- Fearful

## Current Status

 **Prototype Stage**

- Trained on limited datasets  
- Accuracy is not clinically validated  
- Intended as a **baseline research pipeline** for emotion recognition  

---

##  Project Structure

```text
emodio/
â”‚
â”œâ”€â”€ realtime_gui_clean.py      # Real-time emotion recognition GUI
â”œâ”€â”€ predict_voice.py           # Feature extraction and prediction logic
â”œâ”€â”€ train_lstm.py              # LSTM model training script
â”‚
â”œâ”€â”€ model_augmented.h5         # Trained LSTM model
â”œâ”€â”€ scaler.pkl                 # Feature scaler
â”œâ”€â”€ label_encoder.pkl          # Emotion label encoder
â”‚
â”œâ”€â”€ emodio.png / elephant.jpg  # Optional GUI logo
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```
## Quick Start

### Install Dependencies
```bash
pip install numpy sounddevice librosa tensorflow scikit-learn joblib
```

### Train Model (requires datasets)
```bash
python3 train_lstm.py
```

### Run Prediction
```bash
python3 predict_voice.py
```

## Run Real-Time GUI
```bash
python realtime_gui.py
```

## Datasets Used

This project uses publicly available emotion speech datasets:

-RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)
-CREMA-D (Crowd-sourced Emotional Multimodal Actors Dataset)

## Business Potential

This technology can power:
- ğŸ¥ Mental health monitoring apps
- ğŸ“ Customer service quality analysis
- ğŸ® Emotion-responsive games
- ğŸ“š Interactive learning platforms
- ğŸ’¼ HR interview analysis tools
 for detailed business strategy and improvement roadmap.

## Tech Stack

- **Deep Learning:** TensorFlow/Keras LSTM
- **Audio Processing:** Librosa
- **Features:** MFCC, Chroma, Spectral Contrast, Tonnetz




